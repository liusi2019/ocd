{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for the Experiments in Open Category Detection with Guarantees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(devtools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading GitHub repo liusi2019/btloda@master\n",
      "from URL https://api.github.com/repos/liusi2019/btloda/zipball/master\n",
      "Installing btloda\n",
      "'/Users/si/anaconda2/lib/R/bin/R' --no-site-file --no-environ --no-save  \\\n",
      "  --no-restore --quiet CMD INSTALL  \\\n",
      "  '/private/var/folders/0d/ty9fnz017m734hdf0m7ntgcr0000gn/T/RtmpAwfHgo/devtools19158e28fff/liusi2019-btloda-a0793c0'  \\\n",
      "  --library='/Users/si/anaconda2/lib/R/library' --install-tests \n",
      "\n"
     ]
    }
   ],
   "source": [
    "install_github(\"liusi2019/btloda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(btloda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(MASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fuction for getting quantile estimate tau^hat_q using raw ECDF method\n",
    "raw_cdf<- function(datab, datan, alpha, q){\n",
    "    trialv <- sort(c(datan, datab))\n",
    "    F.n <- ecdf(datan)\n",
    "    Fn  <- F.n(trialv)\n",
    "    F.b <- ecdf(datab)\n",
    "    Fb <- F.b(trialv)\n",
    "    Fa <- (Fn - (1-alpha)*Fb)/alpha \n",
    "    if (length(which(Fa <= q))==0){\n",
    "      index <- 1\n",
    "    }else{\n",
    "      index <-max(which(Fa <= q))\n",
    "    }\n",
    "    return(trialv[index])\n",
    "  }\n",
    "\n",
    "## function for getting quantile estimate tau^hat_q using isotonized ECDF method\n",
    "iso_cdf <- function(datab, datan, alpha, q){\n",
    "    trialv <- sort(c(datan, datab))\n",
    "    F.n <- ecdf(datan)\n",
    "    Fn  <- F.n(trialv)\n",
    "    F.b <- ecdf(datab)\n",
    "    Fb <- F.b(trialv)\n",
    "    Fa <- (Fn - (1-alpha)*Fb)/alpha \n",
    "    F.is = isoreg(Fa)$yf ## Computes the Isotonic Estimator of Fa\n",
    "    F.is[which(F.is<=0)]=0  \n",
    "    F.is[which(F.is>=1)]=1\n",
    "    if (length(which(F.is <= q))==0){\n",
    "      index.is <- 1\n",
    "    }else{\n",
    "      index.is <-max(which(F.is <= q))\n",
    "    }\n",
    "    return(trialv[index.is])\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## take as input anomaly scores for nominal and mixture data sets, alpha, q, anomaly scores of the\n",
    "## big nominal and anomaly data set\n",
    "## provide as output the \n",
    "\n",
    "total_result <- function(datab, datan, alpha, q, score_nominal, score_anomaly){\n",
    "    ## estiamte from raw ECDF method\n",
    "    est1 <- raw_cdf(datab, datan, alpha, q)\n",
    "    ## estiamte from isotonized ECDF method\n",
    "    est2 <- iso_cdf(datab, datan, alpha, q)\n",
    "      \n",
    "    result = rep(0, 5)\n",
    "    result[1] <- mean(score_anomaly >= est1)## recall, raw ECDF\n",
    "    result[2] <- mean(score_nominal >= est1)## FPR, the proportion of nominal that are misclassified as alien, raw ECDF\n",
    "    result[3] <- mean(score_anomaly >= est2)## recall, isotonized ECDF\n",
    "    result[4] <- mean(score_nominal >= est2)## FPR, isotonized ECDF\n",
    "    result[5] <- mean(score_nominal >= quantile(score_anomaly, q)) ## ground truth about FPR\n",
    "    return(result)\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following cells are for the experiments on synthetic data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create two big datsets: big_nominal, big_anomaly for calculating ground truth about FPR\n",
    "big_nominal = base::matrix(rnorm(20000*9, 0, 1), nrow = 20000, ncol = 9)\n",
    "big_anomaly = matrix(ncol = 9, nrow = 20000)\n",
    "vmat = matrix(0, ncol = 9, nrow = 9)\n",
    "diag(vmat) = 1\n",
    "for(i in (1:20000)){\n",
    "    center = rep(0, 9)\n",
    "    if(rbinom(1, 1, 0.4)==1){\n",
    "      center[sample(9, 3,replace = F)] = 3\n",
    "      }else{\n",
    "      center[sample(9, 4,replace = F)] = 3\n",
    "      }\n",
    "    big_anomaly[i,] = mvrnorm(1, center, vmat)\n",
    "    } \n",
    "\n",
    "## write them into .csv file for running iforest in linux\n",
    "write.csv(big_nominal, file = paste(\"big_nominal.csv\", sep = \"\"), row.names = FALSE)\n",
    "write.csv(big_anomaly, file = paste(\"big_anomaly.csv\", sep = \"\"), row.names = FALSE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up the sample size n, alien proportion alpha, and q\n",
    "n = 1000\n",
    "vpro = 10\n",
    "alpha = vpro/100  ## anomaly proportion in the mixture data set\n",
    "q = 0.05 ## targetting on q quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  generate nominal and mixture datasets, each of size n\n",
    "dat =  matrix(ncol = 9, nrow = 2*n)\n",
    "vmat = matrix(0, ncol = 9, nrow = 9)\n",
    "diag(vmat) = 1\n",
    "for(i in (1:n*alpha)){\n",
    "  center = rep(0, 9)\n",
    "  if(rbinom(1, 1, 0.4)==1){\n",
    "    center[sample(9, 3,replace = F)] = 3\n",
    "    }else{\n",
    "    center[sample(9, 4,replace = F)] = 3\n",
    "    }\n",
    "  dat[i,] = mvrnorm(1, center, vmat)\n",
    "  } \n",
    "    \n",
    "nnrow <- round(n * (2 - alpha))\n",
    "rvec <- rnorm(9 * nnrow, 0, 1)\n",
    "## the top alpha * n points are alien points \n",
    "dat[(round(n*alpha)+1):(2*n),] <- base::matrix(rvec, nrow = round(n*(2-alpha)), ncol = 9)\n",
    "    \n",
    "data1 <- dat[(n+1):(2*n),] #nominal data set\n",
    "data2 <- dat[1:n,] #mixture data set\n",
    "\n",
    "## write them into .csv file for running iforest using linux    \n",
    "write.csv(data1, file = paste(\"data1.csv\", sep = \"\"), row.names = FALSE)\n",
    "write.csv(data2, file = paste(\"data2.csv\", sep = \"\"), row.names = FALSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The isolation forest implementation used here is from https://github.com/tadeze/osu_iforest (note that this link will provide the correct version after July 1st).\n",
    "### The code in the following cell send command to run iforest in Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## grow iforest using the nominal data set, get out-of-bag anomaly scores for each nominal point\n",
    "## and save the iforest grown\n",
    "system(paste('./iforest','-i', paste('./data1.csv', sep = \"\"),'-o', paste('./depth1.csv', sep = \"\"),'-s', round(0.2*n), '-t 1000 -g -k -b', paste('./forest1.bin',sep = \"\")), wait = TRUE)\n",
    "score1 <- read.csv(paste('./depth1.csv', sep = \"\"), header = TRUE)\n",
    "datab <- as.numeric(unlist(score1))\n",
    "   \n",
    "## run the mixture data set through the saved iforest \n",
    "system(paste('./iforest','-i', paste('./data2.csv', sep = \"\") ,'-o',paste('./depth2.csv', sep = \"\"),'-g -f', paste('./forest1.bin',sep = \"\")), wait = TRUE)\n",
    "score2 <- read.csv(paste('./depth2.csv', sep = \"\"), header = TRUE)\n",
    "datan <- as.numeric(unlist(score2))\n",
    "\n",
    "### run the big nominal and anomaly datasets through the forest\n",
    "system(paste('./iforest','-i', paste('./anomaly','.csv', sep = \"\") ,'-o',paste('./depth_anomaly.csv', sep = \"\"),'-g -f', paste('./forest1.bin',sep = \"\")), wait = TRUE)\n",
    "depth_anomaly <- read.csv(paste('./depth_anomaly.csv', sep = \"\"), header = TRUE)\n",
    "score_anomaly <- as.numeric(unlist(depth_anomaly))\n",
    "    \n",
    "system(paste('./iforest','-i', paste('./nominal','.csv', sep = \"\") ,'-o',paste('./depth_nominal.csv', sep = \"\"),'-g -f', paste('./forest1.bin',sep = \"\")), wait = TRUE)\n",
    "depth_nominal <- read.csv(paste('./depth_nominal.csv', sep = \"\"), header = TRUE)\n",
    "score_nominal <- as.numeric(unlist(depth_nominal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_iforest <- total_result(datab, datan, alpha, q, score_nominal, score_anomaly)\n",
    "output_iforest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This cell below uses R package btloda, which implements the bootstrap and out-of-bag version of LODA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build projections and create histograms using bootstrap of the nominal data set\n",
    "## get out-of-bag anomaly scores for each nominal point\n",
    "bt_out = btloda(data1,sparsity=NA, maxk=1000, keep=NULL, exclude=NULL, debug=F, inf_replace = log(1e-09))\n",
    "\n",
    "bt_datab = bt_out$oob_nll \n",
    "bt_datan = get_neg_ll_all_hist(data2, bt_out$pvh$w, bt_out$pvh$hists, inf_replace = log(1e-09))\n",
    "\n",
    "## get anomaly scores for the big nominal and anomaly data sets using projections and histograms\n",
    "bt_score_nominal = get_neg_ll_all_hist(big_nominal, bt_out$pvh$w, bt_out$pvh$hists, inf_replace = log(1e-09))\n",
    "bt_score_anomaly = get_neg_ll_all_hist(big_anomaly, bt_out$pvh$w, bt_out$pvh$hists, inf_replace = log(1e-09))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_btloda = total_result(bt_datab, bt_datan, alpha, q, bt_score_nominal, bt_score_anomaly)\n",
    "output_btloda"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
